{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64b0eda-32b7-4ef6-aedd-1dd22dd55787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from scipy.stats import anderson\n",
    "import statsmodels\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c58a47-9579-4e3a-a814-88c8b2a53e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateResidualAnalysis(residuals,fits, exog, labeladj=.05):\n",
    "    '''\n",
    "    This takes the output of an OLS fitted model to produce a graphical and statistical residual analysis.\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    plt.title('Residuals vs Fits')\n",
    "    plt.xlabel('Fits')\n",
    "    plt.ylabel('Residuals')\n",
    "    \n",
    "    color = []\n",
    "    for i, txt in enumerate(data.index):\n",
    "        if (residuals[i] > 2*residuals.std()) or (residuals[i] <   -2*residuals.std()):\n",
    "            ax.annotate(txt, (fits[i], residuals[i]),xytext=(fits[i] +labeladj*fits.std() , residuals[i]+labeladj*residuals.std()))\n",
    "            col = 'red'\n",
    "        else: \n",
    "            col = 'blue'\n",
    "        color.append(col)\n",
    "        \n",
    "    plt.scatter(fits,residuals, color=color)\n",
    "    \n",
    "    \n",
    "    ad_results = anderson(residuals)\n",
    "    \n",
    "    if ad_results[0] > ad_results[1][3]:\n",
    "        message = r'Using the Anderson-Darling on the residuals with $\\alpha = .05$, '+ str(np.round(ad_results[0],3))+ ' > '+ str(ad_results[1][3])+'.\\n Therefore the residuals are not normal.'\n",
    "        plt.text(.5, -.25, message, horizontalalignment='center',\n",
    "         verticalalignment='center', transform=ax.transAxes)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        message = r'Using the Anderson-Darling on the residuals with $\\alpha = .05$, '+ str(np.round(ad_results[0],3))+ ' < '+ str(ad_results[1][3])+'.\\n Therefore the residuals are normal.'\n",
    "        plt.text(.5, -.25, message, horizontalalignment='center',\n",
    "         verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "\n",
    "    names = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "\n",
    "    test =statsmodels.stats.diagnostic.het_breuschpagan(residuals,exog)\n",
    "    \n",
    "    \n",
    "    if test[1] > 0.05:\n",
    "        bp_message = 'The p-value of the Breusch-Pagan test is ' + str(test[1]) + '. \\n Therefore, there is heteroskedasticity within the residuals.'\n",
    "        plt.text(.5, -.4, bp_message, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "    else:\n",
    "        bp_message = 'The p-value of the Breusch-Pagan test is ' + str(test[1]) + '. \\n Therefore, there is homoskedacity within the residuals.'\n",
    "        plt.text(.5, -.4, bp_message, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015a8b1d-cf26-4a59-8fc7-d81cd8d6e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneOLSRun(x,y):\n",
    "    '''\n",
    "    We want to take in a set of columns in the X. And a column in the y. \n",
    "    The output should be a one off output of the residual analysis and linear regression results.\n",
    "    '''\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(y.astype(float),x.astype(float))\n",
    "    results = model.fit()\n",
    "    print(results.summary(alpha=.05))\n",
    "    CreateResidualAnalysis(results.resid,results.fittedvalues,results.model.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1aa2c2-dfc6-4433-ad81-6627ffd73760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scale(df,continuous,categorical):\n",
    "    '''\n",
    "    Take in columns of continuous X's and standardize them.\n",
    "    Reurn standardaized df.\n",
    "    '''\n",
    "    new_df = pd.DataFrame()\n",
    "    for name in continuous:\n",
    "        cur_col = df[name]\n",
    "        cur_std = cur_col.std()\n",
    "        cur_mean = cur_col.mean()\n",
    "        cur_col_standardized = (cur_col - cur_mean)/cur_std\n",
    "        new_df[str(name+' Standardized')] = cur_col_standardized\n",
    "    for name in categorical:\n",
    "        new_df[name]= df[name]\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024af567-edb5-463b-9595-db0d8b3cab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateInteractions(df):\n",
    "    '''\n",
    "    Input a dataframe\n",
    "    Return a dataframe with each column multiplied by all other columns in the dataframe\n",
    "    \n",
    "    '''\n",
    "    temp_df = df.copy()\n",
    "    cols = temp_df.columns\n",
    "    for i in range(len(cols)-1):\n",
    "        cur_col = cols[i]\n",
    "        next_cols = cols[i+1:]\n",
    "        for j in range(len(next_cols)):\n",
    "            interaction = cur_col+'*'+next_cols[j]\n",
    "            temp_df[interaction] =  temp_df[cur_col]*temp_df[next_cols[j]] #pay CLOSE attention to operation\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381ac1b0-3d03-43e5-bdd0-fbbd07b916d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FSW(df, x_totest,y,alpha,x=None):\n",
    "    '''x_totest are column names to test. X is set to none, but represents the name of X's to force into the model.'''\n",
    "    '''return columns names to be used?'''\n",
    "    # print(x)\n",
    "    alphas = []\n",
    "    current_testing = []\n",
    "    if x is None: #if we are starting out with a single term model        \n",
    "        for column_index in range(len(x_totest)):\n",
    "            temp_x = df[x_totest[column_index]]\n",
    "            temp_x = sm.add_constant(temp_x)\n",
    "            # print('x is ', x_totest[column_index])\n",
    "            model = sm.OLS(y.astype(float),temp_x.astype(float)) #did as float\n",
    "            results = model.fit()\n",
    "            current_p_value = results.pvalues.iloc[-1]\n",
    "            if math.isnan(current_p_value):\n",
    "                current_p_value = 1000\n",
    "            alphas.append(current_p_value)\n",
    "        best_alpha_index = np.argmin(alphas)\n",
    "        # print(best_alpha_index)\n",
    "        # print(alphas)\n",
    "        if alphas[best_alpha_index] < .05:\n",
    "            x = [x_totest[best_alpha_index]] #add to required\n",
    "            x_totest.remove(x_totest[best_alpha_index]) #remove from testing\n",
    "            return FSW(df, x_totest,y,alpha,x)\n",
    "        else:\n",
    "            return 'No terms meet the alpha threshold for a single term model'\n",
    "    else: #case when we have at least a single order model/terms that must be in the new model.\n",
    "        initial_df = df[x] #create a subset of the x's that have already met the threshold.\n",
    "        for column_index in range(len(x_totest)):\n",
    "            #temp_x = df[x_totest[column_index]]\n",
    "            # print(x_totest[column_index])\n",
    "            combined_df = initial_df.copy()\n",
    "            combined_df[x_totest[column_index]] = df[x_totest[column_index]]\n",
    "            combined_df = sm.add_constant(combined_df)\n",
    "            model = sm.OLS(y.astype(float),combined_df.astype(float))\n",
    "            results = model.fit()\n",
    "            current_p_value = results.pvalues.iloc[-1]\n",
    "            if math.isnan(current_p_value):\n",
    "                current_p_value = 1000\n",
    "            alphas.append(current_p_value)\n",
    "        best_alpha_index = np.argmin(alphas)\n",
    "        # print(best_alpha_index)\n",
    "        # print(alphas)\n",
    "        if alphas[best_alpha_index] < .05:\n",
    "            # print(best_alpha_index)\n",
    "            # print(alphas)\n",
    "            x.append(x_totest[best_alpha_index]) #add to required\n",
    "            x_totest.remove(x_totest[best_alpha_index]) #remove from testing\n",
    "            return FSW(df, x_totest,y,alpha,x) \n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e67fe-117b-43a8-9657-8709ab70cafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
